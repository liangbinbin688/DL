{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "#参数\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "display_step = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "#print(train_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 ,cost=00.131458,W=00000,b=00000\n",
      "Epoch: 0100 ,cost=00.121290,W=00000,b=00000\n",
      "Epoch: 0150 ,cost=00.113019,W=00000,b=00000\n",
      "Epoch: 0200 ,cost=00.106289,W=00000,b=00000\n",
      "Epoch: 0250 ,cost=00.100815,W=00000,b=00000\n",
      "Epoch: 0300 ,cost=00.096361,W=00000,b=00000\n",
      "Epoch: 0350 ,cost=00.092738,W=00000,b=00000\n",
      "Epoch: 0400 ,cost=00.089790,W=00000,b=00000\n",
      "Epoch: 0450 ,cost=00.087392,W=00000,b=00000\n",
      "Epoch: 0500 ,cost=00.085441,W=00000,b=00000\n",
      "Epoch: 0550 ,cost=00.083854,W=00000,b=00000\n",
      "Epoch: 0600 ,cost=00.082562,W=00000,b=00000\n",
      "Epoch: 0650 ,cost=00.081512,W=00000,b=00000\n",
      "Epoch: 0700 ,cost=00.080657,W=00000,b=00000\n",
      "Epoch: 0750 ,cost=00.079962,W=00000,b=00000\n",
      "Epoch: 0800 ,cost=00.079397,W=00000,b=00000\n",
      "Epoch: 0850 ,cost=00.078936,W=00000,b=00000\n",
      "Epoch: 0900 ,cost=00.078562,W=00000,b=00000\n",
      "Epoch: 0950 ,cost=00.078258,W=00000,b=00000\n",
      "Epoch: 1000 ,cost=00.078010,W=00000,b=00000\n",
      "Epoch: 1050 ,cost=00.077808,W=00000,b=00000\n",
      "Epoch: 1100 ,cost=00.077644,W=00000,b=00000\n",
      "Epoch: 1150 ,cost=00.077511,W=00000,b=00000\n",
      "Epoch: 1200 ,cost=00.077402,W=00000,b=00000\n",
      "Epoch: 1250 ,cost=00.077314,W=00000,b=00000\n",
      "Epoch: 1300 ,cost=00.077242,W=00000,b=00000\n",
      "Epoch: 1350 ,cost=00.077184,W=00000,b=00000\n",
      "Epoch: 1400 ,cost=00.077136,W=00000,b=00000\n",
      "Epoch: 1450 ,cost=00.077098,W=00000,b=00000\n",
      "Epoch: 1500 ,cost=00.077066,W=00000,b=00000\n",
      "Epoch: 1550 ,cost=00.077041,W=00000,b=00000\n",
      "Epoch: 1600 ,cost=00.077020,W=00000,b=00000\n",
      "Epoch: 1650 ,cost=00.077003,W=00000,b=00000\n",
      "Epoch: 1700 ,cost=00.076989,W=00000,b=00000\n",
      "Epoch: 1750 ,cost=00.076978,W=00000,b=00000\n",
      "Epoch: 1800 ,cost=00.076969,W=00000,b=00000\n",
      "Epoch: 1850 ,cost=00.076961,W=00000,b=00000\n",
      "Epoch: 1900 ,cost=00.076955,W=00000,b=00000\n",
      "Epoch: 1950 ,cost=00.076950,W=00000,b=00000\n",
      "Epoch: 2000 ,cost=00.076946,W=00000,b=00000\n",
      "Epoch: 2050 ,cost=00.076943,W=00000,b=00000\n",
      "Epoch: 2100 ,cost=00.076940,W=00000,b=00000\n",
      "Epoch: 2150 ,cost=00.076938,W=00000,b=00000\n",
      "Epoch: 2200 ,cost=00.076936,W=00000,b=00000\n",
      "Epoch: 2250 ,cost=00.076935,W=00000,b=00000\n",
      "Epoch: 2300 ,cost=00.076934,W=00000,b=00000\n",
      "Epoch: 2350 ,cost=00.076933,W=00000,b=00000\n",
      "Epoch: 2400 ,cost=00.076932,W=00000,b=00000\n",
      "Epoch: 2450 ,cost=00.076932,W=00000,b=00000\n",
      "Epoch: 2500 ,cost=00.076931,W=00000,b=00000\n",
      "Epoch: 2550 ,cost=00.076931,W=00000,b=00000\n",
      "Epoch: 2600 ,cost=00.076930,W=00000,b=00000\n",
      "Epoch: 2650 ,cost=00.076930,W=00000,b=00000\n",
      "Epoch: 2700 ,cost=00.076930,W=00000,b=00000\n",
      "Epoch: 2750 ,cost=00.076930,W=00000,b=00000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print (\"Epoch: %04d ,cost=%09f,W=%05d,b=%05d\"%((epoch+1),c,sess.run(W),sess.run(b)))\n",
    "            \"\"\"\n",
    "            '\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "            \"\"\"\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=%04d,W=%04d,b=%04d\"%(training_cost,sess.run(W),sess.run(b))) \n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
