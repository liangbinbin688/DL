{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络编程基础\n",
    "\n",
    "### 1.二分分类\n",
    "\n",
    "计算机保存图片的方式：\n",
    "![010](images/010.png)\n",
    "\n",
    "使用一个向量表示就是64*64*3维的特征。输入的特征向量的维度。\n",
    "\n",
    "训练模型常用的符号：\n",
    "\n",
    "![011](images/011.png)\n",
    "\n",
    "\n",
    "### 2.logistic回归\n",
    "\n",
    "logistic回归的思路：\n",
    "\n",
    "![012](images/012.png)\n",
    "\n",
    "\n",
    "w和b是待求的参数，是$x^n+1$维。\n",
    "\n",
    "logistic回归的损失函数：\n",
    "\n",
    "会定义一个不同的损失函数，它起着与误差平方相似的作用。\n",
    "\n",
    "![013](images/013.png)\n",
    "\n",
    "***成本函数等于个样本误差（损失函数）的求和取均值：***\n",
    "\n",
    "![014](images/014.png)\n",
    "\n",
    "\n",
    "### 使用梯度下降算法（精华）\n",
    "\n",
    "![015](images/015.png)\n",
    "\n",
    "成本函数是凸函数，利用凸优化进行最小值的求解。\n",
    "\n",
    "![016](images/016.png)\n",
    "\n",
    "梯度下降算法的详细讲解。\n",
    "\n",
    "\n",
    "在logistic回归中使用梯度下降算法：\n",
    "\n",
    "![019](images/019.png)\n",
    "\n",
    "\n",
    "**对logistic回归的成本函数的解释：**\n",
    "\n",
    "![027](images/027.png)\n",
    "\n",
    "![028](images/028.png)\n",
    "\n",
    "logist回归的成本函数是根据参数最大化样本的概率（最大似然法，样本是独立同分布的），其中由于我们是最小化成本函数，所以我们不直接使用最大似然估计。\n",
    "\n",
    "如上图，通过改变$w_1,w_2,b$的值，最小化损失函数——我们的目标。\n",
    "\n",
    "![020](images/020.png)\n",
    "\n",
    "\n",
    "上述是针对单样本的梯度下降，下面介绍应用到全部数据集的方法：\n",
    "\n",
    "![021](images/021.png)\n",
    "\n",
    "上述方法使用了多个for 循环，不适合在大数据集上使用，下面介绍一种向量化技术减缓这种for循环的使用，提高效率：\n",
    "\n",
    "!\n",
    "向量化是消除for循环的工具；\n",
    "\n",
    "什么是向量化？\n",
    "\n",
    "![022](images/022.png)\n",
    "\n",
    "尽量减少for循环的使用，对使用向量化计算，提高数据处理的并行性。\n",
    "\n",
    "## 向量化实现logistic回归：\n",
    "\n",
    "![024](images/024.png)\n",
    "\n",
    "![025](images/025.png)\n",
    "\n",
    "\n",
    "**注意：根据梯度进行更新$w,b$的值**\n",
    "\n",
    "\n",
    "### 导数\n",
    "\n",
    "常用的求导函数等。\n",
    "\n",
    "\n",
    "### 计算图\n",
    "\n",
    "![017](images/017.png)\n",
    "\n",
    "反向传播的链式法则\n",
    "\n",
    "![018](images/018.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量化时间： 1.0058879852294922 ms\n",
      "循环时间为： 669.6105003356934 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a=np.random.rand(1000000)\n",
    "b=np.random.rand(1000000)\n",
    "\n",
    "tic=time.time()\n",
    "c=np.dot(a,b)\n",
    "toc=time.time()\n",
    "\n",
    "print(\"向量化时间：\",(toc-tic)*1000,\"ms\")\n",
    "tic=time.time()\n",
    "for i in range(1000000):\n",
    "    c+=a[i]*b[i]\n",
    "toc=time.time()\n",
    "\n",
    "print(\"循环时间为：\",(toc-tic)*1000,\"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 广播（python）：\n",
    "\n",
    "\n",
    "广播是将较小的矩阵“广播”到较大矩阵相同的形状尺度上，使它们对等以可以进行数学计算。注意的是较小的矩阵要是较大矩阵的倍数，否则无法使用广播。 \n",
    "\n",
    "案例：\n",
    "\n",
    "![026](images/026.png)\n",
    "\n",
    "计算四种食物中，来自碳水化合物，蛋白质和脂肪的百分比各占多少？\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.    0.    4.4  68. ]\n",
      " [  1.2 104.   52.    8. ]\n",
      " [  1.8 135.   99.    0.9]]\n",
      "[[94.91525424  0.          2.83140283 88.42652796]\n",
      " [ 2.03389831 43.51464435 33.46203346 10.40312094]\n",
      " [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A=np.array([[56.0,0.0,4.4,68.0],[1.2,104.0,52.0,8.0],[1.8,135.0,99.0,0.9]])\n",
    "\n",
    "print(A)\n",
    "\n",
    "cal=A.sum(axis=0)   #axis=0表示操作列，axis=1表示操作行\n",
    "\n",
    "percentage=100*A/cal.reshape(1,4)\n",
    "\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101 102 103 104]\n",
      "[[101 202 303]\n",
      " [104 205 306]]\n"
     ]
    }
   ],
   "source": [
    "#向量加数字  1\n",
    "a=np.array([1,2,3,4])   #广播的例子   \n",
    "b=100\n",
    "c=a+b\n",
    "print(c)\n",
    "\n",
    "#矩阵加向量  2\n",
    "a1=np.array([[1,2,3],[4,5,6]])\n",
    "b1=np.array([100,200,300])\n",
    "\n",
    "c1=a1+b1\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python中的一些规则：\n",
    "\n",
    "+ 如果有一个（m,n）的矩阵，加减乘除一个(1,n)的矩阵，python会默认扩展（1，n）成为(m,n),然后对应项操作，(m,1)矩阵同理；\n",
    "\n",
    "+ 如果一个(m,1)的矩阵，加减乘除一个实数，同上进行扩展。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
