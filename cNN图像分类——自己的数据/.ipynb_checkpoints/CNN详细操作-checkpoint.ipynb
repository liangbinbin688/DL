{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "利用卷积神经网络训练图像数据分为以下几个步骤\n",
    "\n",
    "    读取图片文件\n",
    "    产生用于训练的批次\n",
    "    定义训练的模型（包括初始化参数，卷积、池化层等参数、网络）\n",
    "    训练\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"读取图片\"\"\"\n",
    "def get_files(filename):\n",
    "    class_train = []\n",
    "    label_train = []\n",
    "    for train_class in os.listdir(filename):\n",
    "        for pic in os.listdir(filename+train_class):\n",
    "            class_train.append(filename+train_class+'/'+pic)\n",
    "            label_train.append(train_class)\n",
    "    temp = np.array([class_train,label_train])\n",
    "    temp = temp.transpose()\n",
    "    #shuffle the samples\n",
    "    np.random.shuffle(temp)\n",
    "    #after transpose, images is in dimension 0 and label in dimension 1\n",
    "    image_list = list(temp[:,0])\n",
    "    label_list = list(temp[:,1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    "    #print(label_list)\n",
    "    return image_list,label_list\n",
    "\n",
    "\"\"\"训练批次\"\"\"\n",
    "def get_batches(image,label,resize_w,resize_h,batch_size,capacity):\n",
    "    #convert the list of images and labels to tensor\n",
    "    image = tf.cast(image,tf.string)\n",
    "    label = tf.cast(label,tf.int64)\n",
    "    queue = tf.train.slice_input_producer([image,label])\n",
    "    label = queue[1]\n",
    "    image_c = tf.read_file(queue[0])\n",
    "    image = tf.image.decode_jpeg(image_c,channels = 3)\n",
    "    #resize\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image,resize_w,resize_h)\n",
    "    #(x - mean) / adjusted_stddev\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    image_batch,label_batch = tf.train.batch([image,label],\n",
    "                                             batch_size = batch_size,\n",
    "                                             num_threads = 64,\n",
    "                                             capacity = capacity)\n",
    "    images_batch = tf.cast(image_batch,tf.float32)\n",
    "    labels_batch = tf.reshape(label_batch,[batch_size])\n",
    "    return images_batch,labels_batch\n",
    "\n",
    "\n",
    "\"\"\"定义训练的模型\"\"\"\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev = 0.01))\n",
    "#init weights\n",
    "weights = {\n",
    "    \"w1\":init_weights([3,3,3,16]),\n",
    "    \"w2\":init_weights([3,3,16,128]),\n",
    "    \"w3\":init_weights([3,3,128,256]),\n",
    "    \"w4\":init_weights([4096,4096]),\n",
    "    \"wo\":init_weights([4096,2])\n",
    "    }\n",
    "\n",
    "#init biases\n",
    "biases = {\n",
    "    \"b1\":init_weights([16]),\n",
    "    \"b2\":init_weights([128]),\n",
    "    \"b3\":init_weights([256]),\n",
    "    \"b4\":init_weights([4096]),\n",
    "    \"bo\":init_weights([2])\n",
    "    }\n",
    "\n",
    "def conv2d(x,w,b):\n",
    "    x = tf.nn.conv2d(x,w,strides = [1,1,1,1],padding = \"SAME\")\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def pooling(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "def norm(x,lsize = 4):\n",
    "    return tf.nn.lrn(x,depth_radius = lsize,bias = 1,alpha = 0.001/9.0,beta = 0.75)\n",
    "\n",
    "def mmodel(images):\n",
    "    l1 = conv2d(images,weights[\"w1\"],biases[\"b1\"])\n",
    "    l2 = pooling(l1)\n",
    "    l2 = norm(l2)\n",
    "    l3 = conv2d(l2,weights[\"w2\"],biases[\"b2\"])\n",
    "    l4 = pooling(l3)\n",
    "    l4 = norm(l4)\n",
    "    l5 = conv2d(l4,weights[\"w3\"],biases[\"b3\"])\n",
    "    #same as the batch size\n",
    "    l6 = pooling(l5)\n",
    "    l6 = tf.reshape(l6,[-1,weights[\"w4\"].get_shape().as_list()[0]])\n",
    "    l7 = tf.nn.relu(tf.matmul(l6,weights[\"w4\"])+biases[\"b4\"])\n",
    "    soft_max = tf.add(tf.matmul(l7,weights[\"wo\"]),biases[\"bo\"])\n",
    "    return soft_max\n",
    "def loss(logits,label_batches):\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=label_batches)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    return cost\n",
    "def get_accuracy(logits,labels):\n",
    "    acc = tf.nn.in_top_k(logits,labels,1)\n",
    "    acc = tf.cast(acc,tf.float32)\n",
    "    acc = tf.reduce_mean(acc)\n",
    "    return acc\n",
    "def training(loss,lr):\n",
    "    train_op = tf.train.RMSPropOptimizer(lr,0.9).minimize(loss)\n",
    "    return train_op\n",
    "\n",
    "def run_training():\n",
    "    data_dir = 'C:/Users/wk/Desktop/bky/dataSet/'\n",
    "    image,label = inputData.get_files(data_dir)\n",
    "    image_batches,label_batches = inputData.get_batches(image,label,32,32,16,20)\n",
    "    p = model.mmodel(image_batches)\n",
    "    cost = model.loss(p,label_batches)\n",
    "    train_op = model.training(cost,0.001)\n",
    "    acc = model.get_accuracy(p,label_batches)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess,coord = coord)\n",
    "    \n",
    "    try:\n",
    "        for step in np.arange(1000):\n",
    "            \n",
    "            print(step)\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            _,train_acc,train_loss = sess.run([train_op,acc,cost])\n",
    "            print(\"loss:{} accuracy:{}\".format(train_loss,train_acc))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Done!!!\")\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "###https://www.jianshu.com/p/75a8eb564de7参考链接\n",
    "######https://www.jianshu.com/p/75a8eb564de7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
